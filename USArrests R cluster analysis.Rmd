---
title: "r cluster analysis"
author: "group 2"
date: "2/16/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.


#loading the dataset
```{r}
data("USArrests")
```
#see the size of the data frame
```{r}
dim(USArrests)
```
#summarize
```{r}
summary(USArrests)
```

#states: murder per 100,000
```{r}
USArrests[1]
```
#states: assault per 100,000
```{r}
USArrests[2]
```
#States: % of population living in urban areas
```{r}
USArrests[3]
```
#states: Rape per 100,000
```{r}
USArrests[4]
```
#testing for missing values
```{r}
is.na(USArrests)
```
#there are no missing values


#Data preparation
#1. Subset of the data (Set seed as 123)
#2. Take 15 random rows
#3. Subset the 15 rows
#4. Standardize the variables 
```{r}
set.seed(123)

#take 15 random rows
ss_training <- sample(1:50, 15) 

#subset the 15 rows
df_training <- USArrests[ss_training, ]

#standardize the variables
df.scaled <- scale(df_training)
```

#Euclidean distance
```{r}
dist.eucl <- dist(df.scaled, method = "euclidean")
dist.eucl
```

```{r}
library(factoextra)
distance <- get_dist(df.scaled)
fviz_dist(distance, gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
```

#matrix, subset the first 3 columns & rows
#round values as well
```{r}
round_matrix <- round(as.matrix(distance)[1:3, 1:3], 1)
round_matrix
```

#correlation based distance
```{r}
library(ISLR)
set.seed(123)

distance <- dist(df.scaled)
distance2 <- distance*distance


cor_scale <- cor(t(df.scaled))

minus.cor_scale <- as.dist((1-t(cor_scale)))

op <- summary(minus.cor_scale/distance2)

op
```

#plotting the correlation based distance
```{r}
plot(minus.cor_scale/distance2)
```


#kmeans
```{r}
c <- kmeans(df.scaled, 4, 25)
c
```
#visualize cluster
```{r}
fviz_cluster(c, data=df.scaled)
```
#doesnt hurt to check what would happen if the number of centers were different
```{r}

c_3 <- kmeans(df.scaled, centers = 3, nstart = 25)
c_4 <- kmeans(df.scaled, centers = 4, nstart = 25)
c_5 <- kmeans(df.scaled, centers = 5, nstart = 25)

# plots to compare
p1 <- fviz_cluster(c, geom = "point", data = df.scaled) + ggtitle("k = 2")
p2 <- fviz_cluster(c_3, geom = "point",  data = df.scaled) + ggtitle("k = 3")
p3 <- fviz_cluster(c_4, geom = "point",  data = df.scaled) + ggtitle("k = 4")
p4 <- fviz_cluster(c_5, geom = "point",  data = df.scaled) + ggtitle("k = 5")

library(gridExtra)
grid.arrange(p1, p2, p3, p4, nrow = 2)
```

#determining optimal number of clusters
```{r}
set.seed(123)

fviz_nbclust(df.scaled, kmeans, method = "wss")
```

# The optimal number of clusters is 4.
